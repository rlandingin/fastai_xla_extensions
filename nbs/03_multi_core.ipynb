{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rlandingin/fastai_xla_extensions/blob/master/nbs/03_multi_core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rlandingin/fastai_xla_extensions/blob/master/nbs/03_multi_core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Core XLA extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup torch XLA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the official way to install Pytorch-XLA 1.7 [instructions here](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=CHzziBW5AoZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 53kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fastai\n",
    "\n",
    "Use latest fastai and fastcore versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r\u001b[K     |██████▏                         | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
      "\u001b[?25h  Building wheel for fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "!pip install -Uqq git+https://github.com/fastai/fastai.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.0+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.8.1+cu101\n",
      "fastai==2.2.5\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching BaseOptimizer to be Pickable\n",
    "Patching Base Optimizer `__getstate__` and `__setstate__` whichi is used in pickling\n",
    "the optimizer which should fix the bug in running the learner in multiple TPU cores\n",
    "in XLA by which the  `def _fetch_gradients(optimizer)` in `for param_group in optimizer.__getstate__()['param_groups']:` fails, and this patch fixes the \"copy constructor\" to include the param_groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.basics import patch_to\n",
    "from fastai.optimizer import _BaseOptimizer\n",
    "\n",
    "@patch_to(_BaseOptimizer)\n",
    "def __getstate__(self):\n",
    "    d = {\n",
    "            'state': self.state_dict(),\n",
    "            'param_groups': self.param_groups,\n",
    "        }\n",
    "    if hasattr(self,'defaults'):\n",
    "        d['defaults'] = self.defaults\n",
    "    return d\n",
    "\n",
    "@patch_to(_BaseOptimizer)\n",
    "def __setstate__(self, data):\n",
    "    if 'defaults' in data:\n",
    "        self.defaults = data['defaults']\n",
    "    self.load_state_dict(data['state'])\n",
    "    self.param_groups = data['param_groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#exporti\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "import math\n",
    "from fastcore.basics import store_attr\n",
    "from operator import attrgetter\n",
    "from fastai.data.load import _FakeLoader\n",
    "from fastai.data.core import TfmdDL\n",
    "from fastai.torch_core import TensorBase\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _recast2tensor(o):\n",
    "    if isinstance(o,TensorBase):\n",
    "        # return plain tensor since pl.parallelloader doesn't\n",
    "        # seem to work with tensor subclasses\n",
    "        return torch.from_numpy(o.numpy()) # should not copy tensor\n",
    "    return o\n",
    "\n",
    "def _round_to_multiple(number,multiple):\n",
    "    return int(math.ceil(number/multiple)*multiple)\n",
    "\n",
    "class TPUDistributedDL(TfmdDL):\n",
    "    \"A `TfmdDL` which splits a batch into equal size pieces for each TPU core\"\n",
    "    _default = 'dl'\n",
    "    def __init__(self,dl,rank,world_size, seed=42):\n",
    "        store_attr()\n",
    "        self.bs,self.device,self.num_workers,self.drop_last,self.dataset,self.offs,fake = \\\n",
    "            attrgetter('bs','device','num_workers','drop_last','dataset','offs','fake_l')(dl)\n",
    "        self.fake_l = _FakeLoader(self, fake.pin_memory, fake.num_workers, fake.timeout,\n",
    "                                  persistent_workers=fake.persistent_workers)\n",
    "        self.epoch = 0\n",
    "        random.seed(self.seed)\n",
    "        self.dl.rng = random.Random(random.randint(0,2**32-1))\n",
    "        self.reset_rng()\n",
    "\n",
    "    def reset_rng(self):\n",
    "        random.seed(self.seed + self.epoch)\n",
    "        self.rng = random.Random(random.randint(0,2**32-1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return _round_to_multiple(len(self.dl),self.world_size)//self.world_size\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def get_idxs(self):\n",
    "        idxs = self.dl.get_idxs()\n",
    "        # do your own shuffling which factors in self.epoch + self.seed in\n",
    "        # generating a random sequence (underlying self.dl does not)\n",
    "        if self.shuffle:\n",
    "            idxs = self.shuffle_fn(idxs)\n",
    "        self.n = len(idxs)\n",
    "        # we assumed n was dl.n but we really care about number of idxs\n",
    "        # add extra samples to make it evenly divisible\n",
    "        self.n_padded = _round_to_multiple(self.n,self.world_size)\n",
    "        idxs += (idxs * (self.n_padded//self.n))[:self.n_padded-self.n]\n",
    "        # idx needs to be repeated when n_padded>>n\n",
    "        # slice padded idxs so that each rank gets self.n_padded//self.world_size tensors\n",
    "        start_pos = self.rank*self.n_padded//self.world_size\n",
    "        end_pos = (self.rank+1)*self.n_padded//self.world_size\n",
    "        return idxs[start_pos:end_pos]\n",
    "\n",
    "    def before_iter(self):\n",
    "        self.dl.before_iter()\n",
    "\n",
    "    def randomize(self):\n",
    "        self.reset_rng()\n",
    "        self.dl.randomize()\n",
    "\n",
    "    def after_batch(self,b):\n",
    "        b = self.dl.after_batch(b)\n",
    "        # recast tensor subclasses to plain tensors\n",
    "        # undoing work of self.retain()\n",
    "        tb = [_recast2tensor(o) for o in b]\n",
    "        b = tuple(tb)\n",
    "        return b\n",
    "\n",
    "    def after_iter(self):\n",
    "        self.dl.after_iter()\n",
    "\n",
    "    def create_batches(self,samps):\n",
    "        return self.dl.create_batches(samps)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.dl.device = device\n",
    "        self.device = device\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.basics import patch_to\n",
    "import torch.utils.data.distributed as th_distrib\n",
    "import torch.utils.data as th_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdTorchDS(th_data.Dataset):\n",
    "    def __init__(self, items, x_tfm=None, y_tfm=None):\n",
    "        self.items = items\n",
    "        self.x_tfm = x_tfm\n",
    "        self.y_tfm = y_tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.items[index]\n",
    "        x = self.x_tfm(item) if self.x_tfm is not None else x\n",
    "        y = self.y_tfm(item) if self.y_tfm is not None else y\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.xtras import is_listy\n",
    "import torchvision as thv\n",
    "from operator import itemgetter\n",
    "from fastcore.imports import noop\n",
    "from fastcore.foundation import L\n",
    "\n",
    "def to_list(o):\n",
    "    return [] if o is None else [o] if not is_listy(o) else o\n",
    "\n",
    "def has_setup(tfms):\n",
    "    \"\"\"returns last index if at least 1 `tfm` in `tfms` has a method `setup` else return -1\"\"\"\n",
    "    setups = L(tfms).attrgot('setup',None).argwhere(noop) # get indexes where tfm has `setup` attribute\n",
    "    return -1 if len(setups) == 0 else setups[-1]\n",
    "\n",
    "def run_setups(tfms, items):\n",
    "    \"\"\"run tfm setups including tfm for all items\"\"\"\n",
    "    indx = has_setup(tfms)\n",
    "    if indx == -1: # no setup found\n",
    "        return\n",
    "\n",
    "    for i,tfm in enumerate(tfms):\n",
    "        if hasattr(tfm,'setup'):\n",
    "            tfm.setup(items)\n",
    "        if i < indx:\n",
    "            # tfm items to be fed into next tfm\n",
    "            items = [tfm(item) for item in items]\n",
    "\n",
    "\n",
    "class TorchDatasetBuilder:\n",
    "    def __init__(self, source, get_items, splitter,\n",
    "                x_tfms, y_tfms,\n",
    "                x_type_tfms=None,\n",
    "                x_train_tfms=None, x_test_tfms=None,\n",
    "                do_setup=False):\n",
    "        self.source = source\n",
    "        self.get_items = get_items\n",
    "        self.splitter = splitter\n",
    "        self.do_setup = do_setup\n",
    "        self.x_tfms = to_list(x_tfms)\n",
    "        self.y_tfms = to_list(y_tfms)\n",
    "        self.x_type_tfms = to_list(x_type_tfms)\n",
    "        self.x_train_tfms = to_list(x_train_tfms)\n",
    "        self.x_test_tfms = to_list(x_test_tfms)\n",
    "\n",
    "    def setup(self, items, do_setup=None, setup_x=False):\n",
    "        self.do_setup = do_setup if do_setup is not None else self.do_setup\n",
    "        if self.do_setup:\n",
    "            all_x_tfms = [*self.x_type_tfms, *self.x_train_tfms, *self.x_tfms]\n",
    "            if setup_x:\n",
    "                run_setups(all_x_tfms, items)\n",
    "            run_setups(self.y_tfms, items)\n",
    "            self.do_setup = False\n",
    "\n",
    "    def get_datasets(self, do_setup=None):\n",
    "        self.do_setup = do_setup if do_setup is not None else self.do_setup\n",
    "        items = self.get_items(self.source)\n",
    "        train_idxs, test_idxs = self.splitter(items)\n",
    "\n",
    "        train_items = itemgetter(*train_idxs)(items)\n",
    "        test_items = itemgetter(*test_idxs)(items)\n",
    "        self.setup(train_items)\n",
    "        allx_test_tfms = [*self.x_type_tfms, *self.x_test_tfms, *self.x_tfms]\n",
    "        allx_train_tfms = [*self.x_type_tfms, *self.x_train_tfms, *self.x_tfms]\n",
    "        train_x_tfm = thv.transforms.Compose(allx_train_tfms)\n",
    "        test_x_tfm = thv.transforms.Compose(allx_test_tfms)\n",
    "        y_tfm = thv.transforms.Compose(self.y_tfms)\n",
    "        train_ds = TfmdTorchDS(train_items, x_tfm=train_x_tfm, y_tfm=y_tfm)\n",
    "        test_ds = TfmdTorchDS(test_items, x_tfm=test_x_tfm, y_tfm=y_tfm)\n",
    "        return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.transforms import CategoryMap\n",
    "\n",
    "class VocabularyMapper:\n",
    "    \"\"\"A simplified version of the fastai Categorize Transform\"\"\"\n",
    "    def __init__(self, vocab=None):\n",
    "        self.vocab = vocab\n",
    "        self.c = 0\n",
    "    def setup(self, items):\n",
    "        self.vocab = CategoryMap(items)\n",
    "        self.c = len(self.vocab)\n",
    "    def __call__(self, o):\n",
    "        if self.vocab is None: return o\n",
    "        try:\n",
    "            return torch.tensor(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as thv\n",
    "\n",
    "pil2tensor = thv.transforms.ToTensor()\n",
    "resize28 = thv.transforms.Resize(28)\n",
    "norm = thv.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.core import PILImage\n",
    "from fastai.data.transforms import get_image_files, GrandparentSplitter, parent_label\n",
    "from fastai.data.external import untar_data, URLs\n",
    "\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "mnist_dset_builder =  TorchDatasetBuilder(\n",
    "                source=path, \n",
    "                get_items=get_image_files, \n",
    "                splitter=GrandparentSplitter(),\n",
    "                x_tfms=[resize28,pil2tensor,norm,], \n",
    "                y_tfms=[parent_label,VocabularyMapper(),],\n",
    "                x_type_tfms=PILImage.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "\n",
    "train_ds, test_ds = mnist_dset_builder.get_datasets(do_setup=True)\n",
    "\n",
    "test_eq(len(train_ds),709)\n",
    "test_eq(len(test_ds),699)\n",
    "test_eq(mnist_dset_builder.y_tfms[1].vocab, ('3','7'))\n",
    "test_eq(mnist_dset_builder.y_tfms[1].c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch_to(th_data.DataLoader)\n",
    "def to(self, device):\n",
    "    self.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_torch_dataloaders(train_dataset, test_dataset,\n",
    "                     rank,\n",
    "                     world_size,\n",
    "                     bs,\n",
    "                     num_workers=4,\n",
    "                     distrib=True):\n",
    "    if distrib:\n",
    "        train_sampler = th_distrib.DistributedSampler(\n",
    "            train_dataset,\n",
    "            num_replicas=world_size,\n",
    "            rank=rank,\n",
    "            shuffle=True)\n",
    "        train_loader = th_data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=bs,\n",
    "            sampler=train_sampler,\n",
    "            # shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "        test_sampler = th_distrib.DistributedSampler(\n",
    "            train_dataset,\n",
    "            num_replicas=world_size,\n",
    "            rank=rank,\n",
    "            shuffle=False)\n",
    "\n",
    "        test_loader = th_data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=bs,\n",
    "            sampler=test_sampler,\n",
    "            # shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "    else:\n",
    "        train_loader = th_data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=bs,\n",
    "            # sampler=train_sampler,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "        test_loader = th_data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=bs,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "    dataloaders = DataLoaders(train_loader, test_loader, device=None)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_distributed_dataloaders(dls, rank, world_size):\n",
    "    new_loaders = [TPUDistributedDL(dl, rank=rank, world_size=world_size) for dl in dls.loaders]\n",
    "    return DataLoaders(*new_loaders, path=dls.path, device=dls.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch.utils.hooks\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def wrap_parallel_loader(loader, device):\n",
    "    para_loader = pl.ParallelLoader(loader, [device])\n",
    "    loop_loader = para_loader.per_device_loader(device)\n",
    "    return loop_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.callback.core import TrainEvalCallback\n",
    "from fastai.learner import Recorder\n",
    "import torch\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.learner import CancelValidException, CancelStepException\n",
    "from fastai.torch_core import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XLATrainingCallback(Callback):\n",
    "    run_before = Recorder\n",
    "    run_valid = False\n",
    "    order = -10 # same as TrainEvalCallback (since this replaces TrainEvalCallback)\n",
    "    def __init__(self, device, rank=0):\n",
    "        self.pdevice = device\n",
    "        self.rank = rank\n",
    "\n",
    "    def after_create(self):\n",
    "        self.learn.n_epoch = 1\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Set the iter and epoch counters to 0, put the model and the right device\"\n",
    "        self.learn.epoch,self.learn.loss = 0,tensor(0.)\n",
    "        self.learn.train_iter,self.learn.pct_train = 0,0.\n",
    "        if hasattr(self.dls, 'device'): self.model.to(self.dls.device)\n",
    "        if hasattr(self.model, 'reset'): self.model.reset()\n",
    "        xm.master_print(' ')\n",
    "\n",
    "    def before_epoch(self):\n",
    "        \n",
    "        # set the epoch on train and test to make sure shuffle produces same seq\n",
    "        if hasattr(self.learn.dls.train,'sampler'):\n",
    "            if hasattr(self.learn.dls.train.sampler,'set_epoch'):\n",
    "                self.learn.dls.train.sampler.set_epoch(self.learn.epoch)\n",
    "        elif hasattr(self.learn.dls.train,'set_epoch'):\n",
    "            self.learn.dls.train.set_epoch(self.learn.epoch)\n",
    "            \n",
    "        if hasattr(self.learn.dls.valid,'sampler'):\n",
    "            if hasattr(self.learn.dls.valid.sampler,'set_epoch'):\n",
    "                self.learn.dls.valid.sampler.set_epoch(self.learn.epoch)\n",
    "        elif hasattr(self.learn.dls.valid,'set_epoch'):\n",
    "            self.learn.dls.valid.set_epoch(self.learn.epoch)\n",
    "\n",
    "    def before_train(self):\n",
    "        \"Set the model in training mode\"\n",
    "        self.learn.pct_train=self.epoch/self.n_epoch\n",
    "        self.model.train()\n",
    "        self.learn.training=True\n",
    "        self.learn.dl = wrap_parallel_loader(self.dls.train, self.pdevice)\n",
    "\n",
    "    def before_validate(self):\n",
    "        \"Set the model in validation mode\"\n",
    "#         if self.rank != 0: # no need to compute valid loss/ metric if not master\n",
    "#             raise CancelValidException()\n",
    "        self.model.eval()\n",
    "        self.learn.training=False\n",
    "        self.learn.dl = wrap_parallel_loader(self.dls.valid, self.pdevice)\n",
    "\n",
    "    def before_step(self):\n",
    "        raise CancelStepException()\n",
    "\n",
    "    def after_cancel_step(self):\n",
    "        xm.optimizer_step(self.learn.opt)\n",
    "\n",
    "    def after_batch(self):\n",
    "        \"Update the iter counter (in training mode)\"\n",
    "        self.learn.pct_train += 1./(self.n_iter*self.n_epoch)\n",
    "        self.learn.train_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import copy\n",
    "from fastcore.imports import noop\n",
    "from fastcore.foundation import L\n",
    "from fastai.learner import Metric, AvgMetric, AvgLoss, AvgSmoothLoss\n",
    "import torch\n",
    "import pickle\n",
    "from fastai.torch_core import find_bs, to_detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def update_metric(self:Metric, other_metrics, other_losses):\n",
    "    # dunno how to handle updates for metrics other than AvgMetric, AvgLoss, AvgSmoothLoss\n",
    "    pass\n",
    "\n",
    "@patch\n",
    "def update_metric(self:(AvgMetric,AvgLoss), other_metrics, other_losses):\n",
    "    other_metrics = L(other_metrics)\n",
    "    # other metrics must also be AvgMetric\n",
    "    assert len(other_metrics.map(lambda o: not isinstance(o, (AvgLoss,AvgMetric))).argwhere(noop)) == 0\n",
    "    # other metrics must have same name\n",
    "    assert len(other_metrics.attrgot('name').map(lambda o: o != self.name).argwhere(noop)) == 0\n",
    "    self.total = other_metrics.attrgot('total').sum()\n",
    "    self.count = other_metrics.attrgot('count').sum()\n",
    "\n",
    "def compute_batch_mean_loss(i, other_losses):\n",
    "    batch_losses = other_losses.itemgot(i).attrgot('loss')\n",
    "    batch_sizes =  other_losses.itemgot(i).attrgot('bs')\n",
    "    batch_sum_loss = batch_losses.zipwith(batch_sizes).map(lambda xy: xy[0]*xy[1]).sum()\n",
    "    batch_sum_size = batch_sizes.sum()\n",
    "    batch_mean_loss = batch_sum_loss / batch_sum_size\n",
    "    return batch_mean_loss\n",
    "\n",
    "@patch\n",
    "def update_metric(self:AvgSmoothLoss, other_metrics, other_losses):\n",
    "    # reset count,val and beta to start of train (done by SyncRecorderCallback)    \n",
    "    other_losses = L(other_losses)\n",
    "    n_batches = len(other_losses[0]) # get length of batches from one rank\n",
    "    smooth_losses = []\n",
    "    for i in range(n_batches):\n",
    "        batch_mean_loss = compute_batch_mean_loss(i, other_losses)\n",
    "        # based on definition of AvgSmoothLoss accumulate, taking into account losses\n",
    "        # from across all ranks computed as a mean\n",
    "        self.count += 1\n",
    "        self.val = torch.lerp(batch_mean_loss, self.val, self.beta)\n",
    "        smooth_losses.append(self.value)\n",
    "    self.batch_smooth_losses = smooth_losses\n",
    "    \n",
    "def unpack_sync(res):\n",
    "    return [pickle.loads(o) for o in res]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LossTrackerMetric(Metric):\n",
    "    losses = []\n",
    "    def reset(self):\n",
    "        self.losses.clear()\n",
    "    def accumulate(self, learn):\n",
    "        mean_loss = to_detach(learn.loss.mean(),gather=False)\n",
    "        bs = find_bs(learn.yb)\n",
    "        self.losses.append({'loss': mean_loss, 'bs': bs})\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.learner import _maybe_item\n",
    "from fastprogress.fastprogress import format_time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SyncRecorderCallback(Callback):\n",
    "    \"\"\"Sync metrics from each spawned process update statistics \n",
    "       accordingly so it will display correctly in the progress callback\n",
    "    \"\"\"\n",
    "    order  = 55 # after Recorder, before ProgressCallback\n",
    "    def __init__(self):\n",
    "        self.loss_tracker = LossTrackerMetric() # only track train loss\n",
    "    \n",
    "    def before_fit(self):       \n",
    "        if not xm.is_master_ordinal():\n",
    "            return\n",
    "        if 'progress' in self.learn.cbs.attrgot('name',None):\n",
    "            self._sync_stats_log = self.progress._write_stats\n",
    "        else:\n",
    "            self._sync_stats_log = self.learn.logger\n",
    "        \n",
    "        self.sync_smooth_loss = copy.deepcopy(self.recorder.smooth_loss)\n",
    "    def after_fit(self):\n",
    "        xm.rendezvous('sync recorder after_fit')        \n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.sync_log = copy.copy(self.recorder.log)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        if 'recorder' not in self.learn.cbs.attrgot('name'):\n",
    "            all_metrics = {\n",
    "                'train_mets': L([]),\n",
    "                'valid_mets': L([]),\n",
    "                'losses': L([])\n",
    "            }\n",
    "        else:\n",
    "            all_metrics = {\n",
    "                'train_mets': self.recorder._train_mets, \n",
    "                'valid_mets': self.recorder._valid_mets,\n",
    "                # list of loss,bs for each train batch \n",
    "                #(for recomputing avg smooth loss)\n",
    "                'losses': self.loss_tracker.value\n",
    "            }\n",
    "        # send metrics data to sync ranks across spawned processes     \n",
    "        sync_tag = f'sync_recorder after epoch{self.learn.epoch}'\n",
    "        res = xm.rendezvous(sync_tag, pickle.dumps(all_metrics))\n",
    "        \n",
    "        if xm.is_master_ordinal():\n",
    "            all_metrics = unpack_sync(res)\n",
    "            self._sync_log(all_metrics) # use metrics across ranks to update log\n",
    "            \n",
    "            if hasattr(self.recorder.smooth_loss,'batch_smooth_losses'):\n",
    "                # update recorder losses with smooth losses accounting for losses across ranks\n",
    "                batch_smooth_losses = self.recorder.smooth_loss.batch_smooth_losses\n",
    "                n_batches = len(self.recorder.losses )\n",
    "                # delete last set of batches from current epoch\n",
    "                self.recorder.losses = self.recorder.losses[:n_batches - len(batch_smooth_losses)]\n",
    "                self.recorder.losses += batch_smooth_losses # replace with batch_smooth_losses\n",
    "                \n",
    "            self.learn.smooth_loss = self.recorder.smooth_loss.value\n",
    "            self.learn.final_record = self.sync_log[:1].copy()\n",
    "            del self.recorder.values[-1] # remove last entry added by recorder\n",
    "            self.recorder.values.append(self.learn.final_record) # add updated metrics\n",
    "            if self.recorder.add_time:\n",
    "                updated_time = (time.time() - self.recorder.start_epoch)\n",
    "                self.sync_log.append(format_time(updated_time))\n",
    "            self.recorder.log = self.sync_log\n",
    "            self._sync_stats_log(self.sync_log) # write_stats to output\n",
    "            del self.recorder.iters[-1] # remove last entry added by recorder\n",
    "            self.recorder.iters.append(self.recorder.smooth_loss.count) # add updated smooth loss count\n",
    "            \n",
    "            self.learn.logger = self.orig_logger # restore orig logger after skipping recorder.logger(log) \n",
    "            \n",
    "#         self.learn.final_record = self.log[1:].copy()\n",
    "#         self.values.append(self.learn.final_record)\n",
    "#         if self.add_time: self.log.append(format_time(time.time() - self.start_epoch))\n",
    "#         self.logger(self.log)\n",
    "#         self.iters.append(self.smooth_loss.count)\n",
    "            \n",
    "    def before_train(self):\n",
    "        self.loss_tracker.reset()\n",
    "        if xm.is_master_ordinal():\n",
    "            # find all recorder metrics (count, val, beta) of AvgLossMetric type and store a copy \n",
    "            self.sync_smooth_loss = copy.deepcopy(self.recorder.smooth_loss)\n",
    "        \n",
    "    def after_train(self):      \n",
    "        if xm.is_master_ordinal():\n",
    "            # undo all batch updates (count, val, beta) to AvgLossMetric type and reset them to before train.\n",
    "            self.recorder.smooth_loss.count = self.sync_smooth_loss.count\n",
    "            self.recorder.smooth_loss.val = self.sync_smooth_loss.val\n",
    "            self.recorder.smooth_loss.beta = self.sync_smooth_loss.beta\n",
    "        \n",
    "    def before_validate(self):\n",
    "        pass\n",
    "    \n",
    "    def after_validate(self):\n",
    "        if xm.is_master_ordinal():\n",
    "            self.orig_logger = self.learn.logger\n",
    "            self.learn.logger = noop # write to logger disabled so calling recorder.logger(log) wont print\n",
    "        pass\n",
    "    \n",
    "    def before_batch(self):\n",
    "        pass\n",
    "    \n",
    "    def after_batch(self):\n",
    "        self.loss_tracker.accumulate(self.learn)\n",
    "\n",
    "    def _sync_log(self, all_metrics):\n",
    "        all_metrics = L(all_metrics)\n",
    "        \n",
    "        for i,m in enumerate(self.recorder._train_mets):\n",
    "            m.update_metric(all_metrics.attrgot('train_mets').itemgot(i), all_metrics.attrgot('losses'))\n",
    "            self.sync_log += _maybe_item(m)\n",
    "            \n",
    "        for i,m in enumerate(self.recorder._valid_mets):\n",
    "            m.update_metric(all_metrics.attrgot('valid_mets').itemgot(i), all_metrics.attrgot('losses'))\n",
    "            self.sync_log += _maybe_item(m)   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from fastcore.xtras import join_path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def save(self:Learner, file, **kwargs):\n",
    "    file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "    with_opt = self.opt is not None\n",
    "    state = self.model.state_dict()\n",
    "    if with_opt:\n",
    "        opt_state = self.opt.state_dict()\n",
    "        state = {'model': state, 'opt':opt_state}\n",
    "    xm.save(state, file) # use xm.save instead of torch.save\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "@patch\n",
    "def to_xla(self:Learner,device, rank):\n",
    "    if 'xla_training' not in self.cbs.attrgot('name'):\n",
    "        self.dls.device = None\n",
    "        self.add_cbs(XLATrainingCallback(device, rank))\n",
    "        self.add_cbs(SyncRecorderCallback())\n",
    "    else:\n",
    "        self.xla_training.pdevice = device\n",
    "        self.xla_training.rank = rank\n",
    "\n",
    "    self.remove_cbs(TrainEvalCallback) # replace TrainEval with XLATraining\n",
    "\n",
    "    if rank != 0:\n",
    "        self.remove_cbs(ProgressCallback)\n",
    "  \n",
    "    self.logger = xm.master_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# def DataBlock.dataloaders(self, source, path='.', verbose=False, **kwargs):\n",
    "def build_dataloaders(datablock, source, rank, world_size, device=None, path='.', verbose=False,**kwargs):\n",
    "    dls = datablock.dataloaders(source=source, path=path, device=device, **kwargs)\n",
    "    distrib_dls = make_distributed_dataloaders(dls, rank, world_size)\n",
    "    return distrib_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "#from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExtendedModel:\n",
    "    def __init__(self, arch, normalize, n_out, pretrained):\n",
    "        # store_attr()\n",
    "        self.arch = arch\n",
    "        self.normalize = normalize\n",
    "        self.n_out = n_out\n",
    "        self.pretrained = pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.vision.learner import create_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def xla_cnn_model(arch,\n",
    "                  n_out,\n",
    "                  normalize=True,\n",
    "                  pretrained=True,\n",
    "                **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `arch`\"\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    # set concat_pool to false because AdaptiveConcatPool not supported in XLA\n",
    "    if 'concat_pool' in kwargs:\n",
    "        kwargs.pop('concat_pool',None)\n",
    "    model = create_cnn_model(arch, n_out, pretrained=pretrained, concat_pool=False, **kwargs)\n",
    "    ext_model = ExtendedModel(arch, normalize, n_out, pretrained)\n",
    "    return ext_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.learner import defaults\n",
    "from fastai.vision.learner import model_meta, _add_norm, _default_meta\n",
    "from fastcore.basics import ifnone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def xla_cnn_learner(dls,\n",
    "                    ext_model,\n",
    "                    model,\n",
    "                    loss_func=None,\n",
    "                    opt_func=Adam,\n",
    "                    lr=defaults.lr,\n",
    "                    splitter=None,\n",
    "                    cbs=None,\n",
    "                    metrics=None,\n",
    "                    path=None,\n",
    "                    model_dir='models',\n",
    "                    wd=None,\n",
    "                    wd_bn_bias=False,\n",
    "                    train_bn=True,\n",
    "                    moms=(0.95,0.85,0.95),\n",
    "                    # other model args\n",
    "                    **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `ext_model`\"\n",
    "\n",
    "    meta = model_meta.get(ext_model.arch, _default_meta)\n",
    "    if ext_model.normalize: _add_norm(dls, meta, ext_model.pretrained)\n",
    "\n",
    "    assert ext_model.n_out is not None, \"`n_out` is not defined please pass `n_out`\"\n",
    "    # device = dls.device if hasattr(dls,'device') and dls.device is not None else xm.xla_device()\n",
    "    # device = xm.xla_device()\n",
    "    # model = ext_model.model.to(device) # xmp wrapped model\n",
    "    splitter=ifnone(splitter, meta['split'])\n",
    "    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)\n",
    "    if ext_model.pretrained: learn.freeze()\n",
    "    # keep track of args for loggers\n",
    "    # store_attr('arch,normalize,n_out,pretrained', self=learn, **kwargs)\n",
    "    learn.arch = ext_model.arch\n",
    "    learn.normalize = ext_model.normalize\n",
    "    learn.n_out = ext_model.n_out\n",
    "    learn.pretrained = ext_model.pretrained\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from functools import partial\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.optimizer import SGD, Adam\n",
    "\n",
    "from fastcore.basics import first\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.test_utils import VerboseCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learner(rank):\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    # Scale learning rate to num cores\n",
    "    learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
    "\n",
    "    # Get loss function, optimizer, and model\n",
    "    device = xm.xla_device()\n",
    "    model = WRAPPED_MODEL.to(device)\n",
    "    bs = FLAGS['batch_size']\n",
    "    world_size = xm.xrt_world_size()\n",
    "    dls = build_dataloaders(DATA, PATH, rank, world_size, bs=bs)\n",
    "    # learner = Learner(dls, model, \n",
    "    #                   loss_func=LOSS_FUNC, \n",
    "    #                   opt_func=OPT_FUNC, \n",
    "    #                   metrics=accuracy, \n",
    "    #                   wd=5e-4,\n",
    "    #                   moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']))\n",
    "    learner = xla_cnn_learner(dls, \n",
    "                              EXT_MODEL, \n",
    "                              model, \n",
    "                              loss_func=LOSS_FUNC, \n",
    "                              opt_func=OPT_FUNC, \n",
    "                              metrics=accuracy, \n",
    "                              moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']),\n",
    "                              wd=5e-4)\n",
    "                      \n",
    "    learner.to_xla(device, rank=xm.get_ordinal())\n",
    "    \n",
    "    if xm.is_master_ordinal():\n",
    "        learner.show_training_loop()\n",
    "\n",
    "    epochs = FLAGS['num_epochs']\n",
    "\n",
    "    learner.unfreeze()\n",
    "    xm.master_print('start fit')\n",
    "    learner.fit_one_cycle(epochs, lr_max=slice(learning_rate/10))\n",
    "\n",
    "    # learner.fine_tune(4, base_lr=learning_rate/10)    \n",
    "    \n",
    "    learner.save('stage-1')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    global FLAGS\n",
    "    FLAGS = flags\n",
    "    train_learner(rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import torch\n",
    "from fastcore.transform import DisplayedTransform, Transform\n",
    "from fastcore.basics import store_attr\n",
    "from fastai.vision.core import PILImage, PILBase, image2tensor\n",
    "from fastai.data.block import TransformBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.data.transforms import get_c\n",
    "# from fastai.vision.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.data.transforms import get_image_files, parent_label, GrandparentSplitter\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import Normalize\n",
    "from fastai.vision.core import imagenet_stats\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FUNC = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.optimizer import Adam\n",
    "OPT_FUNC = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(valid_name='testing', train_name='training'),\n",
    "    item_tfms=[Resize(28),],\n",
    "    batch_tfms=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Use fastai resnet18\n",
    "from fastai.vision.learner import create_cnn_model\n",
    "from fastai.vision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from pathlib import Path\n",
    "from fastcore.xtras import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "# FLAGS['batch_size'] = 1024\n",
    "FLAGS['batch_size'] = 128\n",
    "FLAGS['num_workers'] = 4\n",
    "FLAGS['learning_rate'] = 2e-3\n",
    "\n",
    "FLAGS['momentum'] = 0.9\n",
    "FLAGS['num_epochs'] = 5\n",
    "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
    "# FLAGS['num_cores'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = untar_data(URLs.MNIST)\n",
    "# PATH = untar_data(URLs.MNIST_TINY)\n",
    "mdls = DATA.dataloaders(PATH, bs=FLAGS['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from /root/.fastai/data/mnist_png\n",
      "Found 70000 items\n",
      "2 datasets of sizes 60000,10000\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: PILBase.create\n",
      "    starting from\n",
      "      /root/.fastai/data/mnist_png/training/6/51159.png\n",
      "    applying PILBase.create gives\n",
      "      PILImage mode=RGB size=28x28\n",
      "  Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "    starting from\n",
      "      /root/.fastai/data/mnist_png/training/6/51159.png\n",
      "    applying parent_label gives\n",
      "      6\n",
      "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
      "      TensorCategory(6)\n",
      "\n",
      "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
      "\n",
      "\n",
      "Collecting items from /root/.fastai/data/mnist_png\n",
      "Found 70000 items\n",
      "2 datasets of sizes 60000,10000\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "Setting up after_item: Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "    starting from\n",
      "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
      "    applying Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
      "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
      "    applying ToTensor gives\n",
      "      (TensorImage of size 3x28x28, TensorCategory(6))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "    starting from\n",
      "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6]))\n",
      "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
      "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6]))\n"
     ]
    }
   ],
   "source": [
    "DATA.summary(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d0d4c2e45d435098b53bbf04b7b746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EXT_MODEL, custom_model = xla_cnn_model(resnet18,\n",
    "                                        n_out=get_c(mdls), \n",
    "                                        pretrained=True, \n",
    "                                        normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only instantiate model weights once in memory.\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERIAL_EXEC = xmp.MpSerialExecutor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [XLATrainingCallback, Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [XLATrainingCallback, Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [XLATrainingCallback, Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_batch   : [SyncRecorderCallback]\n",
      "         - after_pred     : []\n",
      "         - after_loss     : []\n",
      "         - before_backward: []\n",
      "         - before_step    : [XLATrainingCallback]\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [XLATrainingCallback, Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [XLATrainingCallback, Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, SyncRecorderCallback, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder, SyncRecorderCallback]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [SyncRecorderCallback, ProgressCallback]\n",
      "start fit\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.074850</td>\n",
       "      <td>0.307088</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.307199</td>\n",
       "      <td>0.066054</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122634</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063536</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>0.988100</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044081</td>\n",
       "      <td>0.041158</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 370 ms, sys: 182 ms, total: 552 ms\n",
      "Wall time: 9min 51s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "# !rm -f /content/models/stage-1.pth\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
    "          start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlearner = Learner(mdls, custom_model, \n",
    "#                     loss_func=LOSS_FUNC, \n",
    "#                     opt_func=OPT_FUNC, \n",
    "#                     metrics=accuracy, \n",
    "#                     wd=5e-4,\n",
    "#                     moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']))\n",
    "mlearner = xla_cnn_learner(mdls, \n",
    "                      EXT_MODEL, \n",
    "                      custom_model, \n",
    "                      loss_func=LOSS_FUNC, \n",
    "                      opt_func=OPT_FUNC, \n",
    "                      metrics=accuracy, \n",
    "                      moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']),\n",
    "                      wd=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f851547e4e0>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab                    \n",
    "mlearner.load('stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlearner.dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import one_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_param(mlearner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.040880393236875534, 0.9873999953269958]\n",
      "CPU times: user 30.8 s, sys: 695 ms, total: 31.4 s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "valid_metrics = mlearner.validate();print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlearner.dls.device = master_device\n",
    "# mlearner.model.to(master_device)\n",
    "# mlearner.opt = None\n",
    "# mlearner.create_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# valid_metrics = mlearner.validate(); valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlearner.dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_param(mlearner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
