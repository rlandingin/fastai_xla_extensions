{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "03_multi_core.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlandingin/fastai_xla_extensions/blob/multi-core-impl/nbs/03_multi_core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftg-xxJvgxCR"
      },
      "source": [
        "#default_exp multi_core"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HdzqYFBgxCT"
      },
      "source": [
        "# Multi Core XLA extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibTpWSBfgxCa"
      },
      "source": [
        "## Setup torch XLA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV182O4ugxCa"
      },
      "source": [
        "This is the official way to install Pytorch-XLA 1.7 [instructions here](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=CHzziBW5AoZH)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53lrJMDn9Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d440b0-92b8-4c0d-8827-a4c51b7dc4d5"
      },
      "source": [
        "#colab\n",
        "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 133.6MB 31kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsHVFGHSgxCY"
      },
      "source": [
        "## Install fastai\n",
        "\n",
        "Use latest fastai and fastcore versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5brhMy3uzfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2577b3da-cb86-4355-c343-ca4c4a52aa46"
      },
      "source": [
        "#colab\n",
        "!pip install -Uqq git+https://github.com/fastai/fastai.git "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-maBHnlmDPVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8829fc1c-ef3f-4239-dd74-a745f0d525e2"
      },
      "source": [
        "#hide\n",
        "#colab\n",
        "!curl -s https://course19.fast.ai/setup/colab | bash"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLJEMVZFS2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da5cafe-ff98-497a-a820-a23be08eff5a"
      },
      "source": [
        "#hide\n",
        "!pip freeze | grep torch\n",
        "!pip freeze | grep fast"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.7.0+cu101\n",
            "torch-xla==1.7\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.8.1+cu101\n",
            "fastai==2.2.5\n",
            "fastcore==1.3.18\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnDq_CqPgxCh"
      },
      "source": [
        "## Patching BaseOptimizer to be Pickable\n",
        "Patching Base Optimizer `__getstate__` and `__setstate__` whichi is used in pickling\n",
        "the optimizer which should fix the bug in running the learner in multiple TPU cores\n",
        "in XLA by which the  `def _fetch_gradients(optimizer)` in `for param_group in optimizer.__getstate__()['param_groups']:` fails, and this patch fixes the \"copy constructor\" to include the param_groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApl16-1tZst"
      },
      "source": [
        "#export\n",
        "from fastcore.basics import patch_to\n",
        "from fastai.optimizer import _BaseOptimizer\n",
        "\n",
        "@patch_to(_BaseOptimizer)\n",
        "def __getstate__(self):\n",
        "    d = {\n",
        "            'state': self.state_dict(),\n",
        "            'param_groups': self.param_groups,\n",
        "        }\n",
        "    if hasattr(self,'defaults'): \n",
        "        d['defaults'] = self.defaults\n",
        "    return d\n",
        "\n",
        "@patch_to(_BaseOptimizer)\n",
        "def __setstate__(self, data):\n",
        "    if 'defaults' in data:\n",
        "        self.defaults = data['defaults']\n",
        "    self.load_state_dict(data['state'])\n",
        "    self.param_groups = data['param_groups']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Micd3xZvoA-c"
      },
      "source": [
        "#exporti\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as th_data\n",
        "from fastcore.foundation import L\n",
        "from pathlib import Path\n",
        "from fastcore.xtras import *\n",
        "from fastcore.transform import Pipeline\n",
        "from fastai.data.core import DataLoaders\n",
        "from functools import partial\n",
        "import torch.utils.data.distributed as torch_distrib\n",
        "\n",
        "from pathlib import Path\n",
        "import fastcore.xtras\n",
        "import math\n",
        "from fastcore.basics import store_attr\n",
        "from operator import attrgetter\n",
        "from fastai.data.load import _FakeLoader\n",
        "from fastai.data.core import TfmdDL\n",
        "from fastai.torch_core import find_bs, TensorBase\n",
        "import random\n",
        "import torch\n",
        "from fastai.data.load import _loaders\n",
        "from fastai.torch_core import to_device\n",
        "from fastcore.basics import first\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmUS-lYC9Ea8"
      },
      "source": [
        "#export\n",
        "def _recast2tensor(o):\n",
        "    if isinstance(o,TensorBase):\n",
        "        # return plain tensor since pl.parallelloader doesn't\n",
        "        # seem to work with tensor subclasses\n",
        "        return torch.tensor(o.numpy())\n",
        "    return o\n",
        "\n",
        "def _round_to_multiple(number,multiple): \n",
        "    return int(math.ceil(number/multiple)*multiple)\n",
        "\n",
        "class TPUDistributedDL(TfmdDL):\n",
        "    \"A `TfmdDL` which splits a batch into equal size pieces for each TPU core\"\n",
        "    _default = 'dl'\n",
        "    def __init__(self,dl,rank,world_size, seed=42):\n",
        "        store_attr()\n",
        "        self.bs,self.device,self.num_workers,self.drop_last,self.dataset,self.offs,fake = \\\n",
        "            attrgetter('bs','device','num_workers','drop_last','dataset','offs','fake_l')(dl)\n",
        "        self.fake_l = _FakeLoader(self, fake.pin_memory, fake.num_workers, fake.timeout, \n",
        "                                  persistent_workers=fake.persistent_workers)\n",
        "        self.epoch = 0\n",
        "        random.seed(self.seed)\n",
        "        self.dl.rng = random.Random(random.randint(0,2**32-1))\n",
        "        self.reset_rng()\n",
        "\n",
        "    def reset_rng(self):\n",
        "        random.seed(self.seed + self.epoch)\n",
        "        self.rng = random.Random(random.randint(0,2**32-1))\n",
        "\n",
        "    def __len__(self): \n",
        "        return _round_to_multiple(len(self.dl),self.world_size)//self.world_size\n",
        "\n",
        "    def set_epoch(self, epoch):\n",
        "        self.epoch = epoch\n",
        "\n",
        "    def get_idxs(self):\n",
        "        idxs = self.dl.get_idxs()\n",
        "        # do your own shuffling which factors in self.epoch + self.seed in\n",
        "        # generating a random sequence (underlying self.dl does not)\n",
        "        if self.shuffle: \n",
        "            idxs = self.shuffle_fn(idxs)\n",
        "        self.n = len(idxs)              \n",
        "        # we assumed n was dl.n but we really care about number of idxs\n",
        "        # add extra samples to make it evenly divisible\n",
        "        self.n_padded = _round_to_multiple(self.n,self.world_size)\n",
        "        idxs += (idxs * (self.n_padded//self.n))[:self.n_padded-self.n] \n",
        "        # idx needs to be repeated when n_padded>>n\n",
        "        # slice padded idxs so that each rank gets self.n_padded//self.world_size tensors\n",
        "        start_pos = self.rank*self.n_padded//self.world_size\n",
        "        end_pos = (self.rank+1)*self.n_padded//self.world_size\n",
        "        return idxs[start_pos:end_pos]\n",
        "\n",
        "    def before_iter(self):\n",
        "        self.dl.before_iter()\n",
        "\n",
        "    def randomize(self): \n",
        "        self.reset_rng()\n",
        "        self.dl.randomize()\n",
        "\n",
        "    def after_batch(self,b):\n",
        "        b = self.dl.after_batch(b)\n",
        "        # recast tensor subclasses to plain tensors\n",
        "        # undoing work of self.retain()\n",
        "        tb = [_recast2tensor(o) for o in b]\n",
        "        b = tuple(tb)\n",
        "        return b\n",
        "\n",
        "    def after_iter(self): \n",
        "        self.dl.after_iter()\n",
        "\n",
        "    def create_batches(self,samps): \n",
        "        return self.dl.create_batches(samps)\n",
        "\n",
        "    def to(self, device):\n",
        "        self.dl.device = device\n",
        "        self.device = device\n",
        "        return self\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RStThuhf8rxb"
      },
      "source": [
        "#export\n",
        "def make_distributed_dataloaders(dls, rank, world_size):\n",
        "    new_loaders = []\n",
        "    for i,dl in enumerate(dls.loaders):\n",
        "        if i == 0:\n",
        "            use_rank = rank\n",
        "            use_size = world_size\n",
        "        else: \n",
        "            # for now, in validation, use all samples since only rank 0 computes\n",
        "            # the valid loss and metrics\n",
        "            # TODO: figure out a way to consolidate valid loss and metrics across\n",
        "            # ranks to make distribute batches across multi cores (and reduce number\n",
        "            # of batches per rank -- which should speed up validation)\n",
        "            use_rank = 0\n",
        "            use_size = 1         \n",
        "        dl = TPUDistributedDL(dl,\n",
        "                            rank=use_rank, \n",
        "                            world_size=use_size)\n",
        "        new_loaders += [dl]\n",
        "    return DataLoaders(*new_loaders, path=dls.path, device=dls.device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyhvUv_p1zkC"
      },
      "source": [
        "#exporti\n",
        "from fastai.torch_core import default_device, apply\n",
        "import torch \n",
        "from fastcore.xtras import is_listy\n",
        "import torch\n",
        "import torch.utils.hooks\n",
        "from fastcore.basics import patch\n",
        "from fastai.torch_core import TensorBase\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfcvERSmoW3n"
      },
      "source": [
        "#export\n",
        "def wrap_parallel_loader(loader, device):\n",
        "    para_loader = pl.ParallelLoader(loader, [device])\n",
        "    loop_loader = para_loader.per_device_loader(device)\n",
        "    return loop_loader"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C81ZkqX-KnZ"
      },
      "source": [
        "#exporti\n",
        "from fastai.callback.core import TrainEvalCallback\n",
        "from fastai.learner import Recorder\n",
        "from fastai.torch_core import one_param\n",
        "import torch\n",
        "from fastai.callback.core import Callback\n",
        "from fastai.learner import CancelTrainException, CancelValidException, CancelStepException\n",
        "from fastai.torch_core import tensor, TensorCategory"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQN6muqukJnE"
      },
      "source": [
        "#export\n",
        "class XLATrainingCallback(Callback):\n",
        "    run_before = Recorder\n",
        "    run_valid = False\n",
        "    order = -10 # same as TrainEvalCallback (since this replaces TrainEvalCallback)\n",
        "    def __init__(self, device, rank=0):\n",
        "        self.pdevice = device\n",
        "        self.rank = rank\n",
        "\n",
        "    def after_create(self):\n",
        "        self.learn.n_epoch = 1  \n",
        "\n",
        "    def before_fit(self):\n",
        "        \"Set the iter and epoch counters to 0, put the model and the right device\"\n",
        "        self.learn.epoch,self.learn.loss = 0,tensor(0.)\n",
        "        self.learn.train_iter,self.learn.pct_train = 0,0.\n",
        "        if hasattr(self.dls, 'device'): self.model.to(self.dls.device)\n",
        "        if hasattr(self.model, 'reset'): self.model.reset()\n",
        "        xm.master_print(' ')\n",
        "\n",
        "    def before_epoch(self):\n",
        "        # set the epoch on train only to make sure shuffle produces same seq \n",
        "        # across all ranks\n",
        "        if hasattr(self.learn.dls.train,'sampler'):\n",
        "            if hasattr(self.learn.dls.train.sampler,'set_epoch'):\n",
        "                self.learn.dls.train.sampler.set_epoch(self.learn.epoch) \n",
        "        elif hasattr(self.learn.dls.train,'set_epoch'):\n",
        "            self.learn.dls.train.set_epoch(self.learn.epoch)\n",
        "\n",
        "    def before_train(self):\n",
        "        \"Set the model in training mode\"\n",
        "        self.learn.pct_train=self.epoch/self.n_epoch\n",
        "        self.model.train()\n",
        "        self.learn.training=True\n",
        "        self.learn.dl = wrap_parallel_loader(self.dls.train, self.pdevice)\n",
        "\n",
        "    def before_validate(self):\n",
        "        \"Set the model in validation mode\"\n",
        "        if self.rank != 0: # no need to compute valid loss/ metric if not master\n",
        "            raise CancelValidException()    \n",
        "        self.model.eval()\n",
        "        self.learn.training=False\n",
        "        self.learn.dl = wrap_parallel_loader(self.dls.valid, self.pdevice)\n",
        "\n",
        "    def before_step(self):\n",
        "        raise CancelStepException()\n",
        "\n",
        "    def after_cancel_step(self):\n",
        "        xm.optimizer_step(self.learn.opt)\n",
        "\n",
        "    def after_batch(self):\n",
        "        \"Update the iter counter (in training mode)\"\n",
        "        self.learn.pct_train += 1./(self.n_iter*self.n_epoch)\n",
        "        self.learn.train_iter += 1  \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QO1qlyiOEPf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v5-GB25_Y_b"
      },
      "source": [
        "#exporti\n",
        "from fastcore.imports import noop\n",
        "from fastcore.basics import patch\n",
        "from fastai.learner import Learner\n",
        "from fastai.callback.progress import ProgressCallback\n",
        "from fastcore.xtras import join_path_file\n",
        "from fastai.torch_core import get_model\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjjUIUovZJfX"
      },
      "source": [
        "#export\n",
        "\n",
        "@patch\n",
        "def save(self:Learner, file, **kwargs):\n",
        "    file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
        "    with_opt = self.opt is not None  \n",
        "    state = self.model.state_dict()\n",
        "    if with_opt:\n",
        "        opt_state = self.opt.state_dict() \n",
        "        state = {'model': state, 'opt':opt_state}\n",
        "    xm.save(state, file) # use xm.save instead of torch.save\n",
        "    return file\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLU7Y-X97TxR"
      },
      "source": [
        "#export \n",
        "\n",
        "@patch\n",
        "def to_xla(self:Learner,device, rank):\n",
        "    if 'xla_training' not in self.cbs.attrgot('name'):\n",
        "        self.dls.device = None\n",
        "        self.add_cbs(XLATrainingCallback(device, rank))\n",
        "    else:\n",
        "        self.xla_training.pdevice = device\n",
        "        self.xla_training.rank = rank\n",
        "\n",
        "    self.remove_cbs(TrainEvalCallback) # replace TrainEval with XLATraining\n",
        "\n",
        "    if rank != 0:\n",
        "        self.remove_cbs(ProgressCallback)\n",
        "    self.logger = xm.master_print"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLSy5nkmc2KT"
      },
      "source": [
        "#export\n",
        "\n",
        "# def DataBlock.dataloaders(self, source, path='.', verbose=False, **kwargs):\n",
        "def build_dataloaders(datablock, source, rank, world_size, device=None, path='.', verbose=False,**kwargs):\n",
        "    dls = datablock.dataloaders(source=source, path=path, device=device, **kwargs)\n",
        "    distrib_dls = make_distributed_dataloaders(dls, rank, world_size)\n",
        "    return distrib_dls\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLk-ZkOEzhLp"
      },
      "source": [
        "#exporti\n",
        "from fastcore.basics import store_attr"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbDOW9RAmRX"
      },
      "source": [
        "#export\n",
        "class ExtendedModel:\n",
        "    def __init__(self, arch, normalize, n_out, pretrained):\n",
        "        # store_attr()\n",
        "        self.arch = arch\n",
        "        self.normalize = normalize\n",
        "        self.n_out = n_out\n",
        "        self.pretrained = pretrained"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IvufIGjz0Ps"
      },
      "source": [
        "#exporti\n",
        "from fastai.data.transforms import get_c\n",
        "from fastai.vision.learner import create_cnn_model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGTaao-57szf"
      },
      "source": [
        "#export\n",
        "def xla_cnn_model(arch,\n",
        "                  n_out,\n",
        "                  normalize=True,  \n",
        "                  pretrained=True, \n",
        "                **kwargs):\n",
        "    \"Build a convnet style learner from `dls` and `arch`\"\n",
        "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
        "    # set concat_pool to false because AdaptiveConcatPool not supported in XLA\n",
        "    if 'concat_pool' in kwargs:\n",
        "        kwargs.pop('concat_pool',None)\n",
        "    model = create_cnn_model(arch, n_out, pretrained=pretrained, concat_pool=False, **kwargs)\n",
        "    ext_model = ExtendedModel(arch, normalize, n_out, pretrained)\n",
        "    return ext_model, model\n",
        "    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGHjbdEoBoRD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1F0YX0Q0U_7"
      },
      "source": [
        "#exporti\n",
        "from fastai.optimizer import Adam\n",
        "from fastai.learner import defaults\n",
        "from fastai.vision.learner import model_meta, _add_norm, _default_meta\n",
        "from fastcore.basics import ifnone"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7RTTAKFBCjP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq63TDPV8O-W"
      },
      "source": [
        "#export\n",
        "def xla_cnn_learner(dls, \n",
        "                    ext_model, \n",
        "                    model,\n",
        "                    loss_func=None, \n",
        "                    opt_func=Adam, \n",
        "                    lr=defaults.lr, \n",
        "                    splitter=None, \n",
        "                    cbs=None, \n",
        "                    metrics=None, \n",
        "                    path=None,\n",
        "                    model_dir='models', \n",
        "                    wd=None, \n",
        "                    wd_bn_bias=False, \n",
        "                    train_bn=True, \n",
        "                    moms=(0.95,0.85,0.95),\n",
        "                    # other model args\n",
        "                    **kwargs):\n",
        "    \"Build a convnet style learner from `dls` and `ext_model`\"\n",
        "\n",
        "    meta = model_meta.get(ext_model.arch, _default_meta)\n",
        "    if ext_model.normalize: _add_norm(dls, meta, ext_model.pretrained)\n",
        "\n",
        "    assert ext_model.n_out is not None, \"`n_out` is not defined please pass `n_out`\"\n",
        "    # device = dls.device if hasattr(dls,'device') and dls.device is not None else xm.xla_device()\n",
        "    # device = xm.xla_device()\n",
        "    # model = ext_model.model.to(device) # xmp wrapped model \n",
        "    splitter=ifnone(splitter, meta['split'])\n",
        "    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
        "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
        "                   moms=moms)\n",
        "    if ext_model.pretrained: learn.freeze()\n",
        "    # keep track of args for loggers\n",
        "    # store_attr('arch,normalize,n_out,pretrained', self=learn, **kwargs)\n",
        "    learn.arch = ext_model.arch\n",
        "    learn.normalize = ext_model.normalize\n",
        "    learn.n_out = ext_model.n_out\n",
        "    learn.pretrained = ext_model.pretrained\n",
        "    return learn\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkCSxNkuwodp"
      },
      "source": [
        "## Test out the code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIYME3Bz-Knc"
      },
      "source": [
        "#hide\n",
        "from functools import partial\n",
        "from fastai.metrics import accuracy\n",
        "from fastai.optimizer import SGD, Adam\n",
        "\n",
        "from fastcore.basics import first\n",
        "from fastai.callback.schedule import *\n",
        "from fastai.test_utils import VerboseCallback\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJK9oFg4MVAi"
      },
      "source": [
        "def train_learner(rank):\n",
        "    torch.manual_seed(1)\n",
        "\n",
        "    # Scale learning rate to num cores\n",
        "    learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "    # Get loss function, optimizer, and model\n",
        "    device = xm.xla_device()\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "    bs = FLAGS['batch_size']\n",
        "    world_size = xm.xrt_world_size()\n",
        "    dls = build_dataloaders(DATA, PATH, rank, world_size, bs=bs)\n",
        "    # learner = Learner(dls, model, \n",
        "    #                   loss_func=LOSS_FUNC, \n",
        "    #                   opt_func=OPT_FUNC, \n",
        "    #                   metrics=accuracy, \n",
        "    #                   wd=5e-4,\n",
        "    #                   moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']))\n",
        "    learner = xla_cnn_learner(dls, \n",
        "                              EXT_MODEL, \n",
        "                              model, \n",
        "                              loss_func=LOSS_FUNC, \n",
        "                              opt_func=OPT_FUNC, \n",
        "                              metrics=accuracy, \n",
        "                              moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']),\n",
        "                              wd=5e-4)\n",
        "                      \n",
        "    learner.to_xla(device, rank=xm.get_ordinal())\n",
        "                           \n",
        "    epochs = FLAGS['num_epochs']\n",
        "\n",
        "    learner.unfreeze()\n",
        "    learner.fit_one_cycle(epochs, lr_max=slice(learning_rate/10))\n",
        "\n",
        "    # learner.fine_tune(4, base_lr=learning_rate/10)    \n",
        "    \n",
        "    learner.save('stage-1')  \n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2nL4HmloEyl"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    global FLAGS\n",
        "    FLAGS = flags\n",
        "    train_learner(rank)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxafi-nogR0P"
      },
      "source": [
        "#hide\n",
        "import torch\n",
        "from fastcore.transform import DisplayedTransform, Transform\n",
        "from fastcore.basics import store_attr\n",
        "from fastai.vision.core import PILImage, PILBase, image2tensor\n",
        "from fastai.data.block import TransformBlock"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdfCw9OWsgEX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBaA-8DyVV3_"
      },
      "source": [
        "#hide\n",
        "from fastai.data.transforms import get_c\n",
        "# from fastai.vision.all import *\n",
        "from fastai.data.block import DataBlock, CategoryBlock\n",
        "from fastai.vision.data import ImageBlock\n",
        "from fastai.data.transforms import get_image_files, parent_label, GrandparentSplitter\n",
        "from fastai.vision.augment import Resize, aug_transforms\n",
        "from fastai.data.external import untar_data, URLs\n",
        "from fastai.data.transforms import Normalize\n",
        "from fastai.vision.core import imagenet_stats"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pxqjcGUo8p2"
      },
      "source": [
        "LOSS_FUNC = nn.CrossEntropyLoss()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23CfyVhuhswS"
      },
      "source": [
        "OPT_FUNC = Adam"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeoBGaxRWvQK"
      },
      "source": [
        "DATA = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(valid_name='testing', train_name='training'),\n",
        "    item_tfms=[Resize(28),],\n",
        "    batch_tfms=[]\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgh0Q0h3L5oj"
      },
      "source": [
        "#hide\n",
        "# Use fastai resnet18\n",
        "from fastai.vision.learner import create_cnn_model\n",
        "from fastai.vision.models import resnet18"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKcfNzyUhMKX"
      },
      "source": [
        "#hide\n",
        "from pathlib import Path\n",
        "from fastcore.xtras import *\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi0nP_NQv_si"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSRaAgHFth2X"
      },
      "source": [
        "import os\n",
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "# FLAGS['batch_size'] = 1024\n",
        "FLAGS['batch_size'] = 128\n",
        "FLAGS['num_workers'] = 4\n",
        "FLAGS['learning_rate'] = 2e-3\n",
        "\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 5\n",
        "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "# FLAGS['num_cores'] = 1 "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19o6dPgMHbSg"
      },
      "source": [
        "PATH = untar_data(URLs.MNIST)\n",
        "# PATH = untar_data(URLs.MNIST_TINY)\n",
        "mdls = DATA.dataloaders(PATH, bs=FLAGS['batch_size'])"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5X_mylR4oGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d3307e-855f-4075-cb07-cb337e8b6231"
      },
      "source": [
        "DATA.summary(PATH)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/3/12933.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/3/12933.png\n",
            "    applying parent_label gives\n",
            "      3\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(3)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(3))\n",
            "\n",
            "\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(3))\n",
            "    applying Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(3))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(3))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([3, 3, 3, 3]))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([3, 3, 3, 3]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W28CCPAsv1po"
      },
      "source": [
        "EXT_MODEL, custom_model = xla_cnn_model(resnet18,\n",
        "                                        n_out=get_c(mdls), \n",
        "                                        pretrained=True, \n",
        "                                        normalize=False)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbwZiK1wHXCR"
      },
      "source": [
        "\n",
        "# custom_model = create_cnn_model(resnet18, get_c(mdls), \n",
        "#                                 pretrained=True,\n",
        "#                                 concat_pool=False)\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8h1S0U7Jqs"
      },
      "source": [
        "# Only instantiate model weights once in memory.\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(custom_model)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz4JUeQLtTWP"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bila9S7CPU6d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWsDceGV8EAt",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ca6dd783-22cc-4f30-dde8-6d0f17ab9599"
      },
      "source": [
        "#colab\n",
        "%%time\n",
        "!rm -f /content/models/stage-1.pth\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.341644</td>\n",
              "      <td>0.330447</td>\n",
              "      <td>0.898900</td>\n",
              "      <td>00:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.422134</td>\n",
              "      <td>0.054140</td>\n",
              "      <td>0.982200</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.171844</td>\n",
              "      <td>0.040194</td>\n",
              "      <td>0.985900</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078365</td>\n",
              "      <td>0.036932</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.044823</td>\n",
              "      <td>0.037975</td>\n",
              "      <td>0.987700</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 468 ms, sys: 325 ms, total: 793 ms\n",
            "Wall time: 1min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWXz9cNmvlvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ee2fb3-6de0-4de6-b356-621feb9c3298"
      },
      "source": [
        "# mlearner = Learner(mdls, custom_model, \n",
        "#                     loss_func=LOSS_FUNC, \n",
        "#                     opt_func=OPT_FUNC, \n",
        "#                     metrics=accuracy, \n",
        "#                     wd=5e-4,\n",
        "#                     moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']))\n",
        "mlearner = xla_cnn_learner(mdls, \n",
        "                      EXT_MODEL, \n",
        "                      custom_model, \n",
        "                      loss_func=LOSS_FUNC, \n",
        "                      opt_func=OPT_FUNC, \n",
        "                      metrics=accuracy, \n",
        "                      moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']),\n",
        "                      wd=5e-4)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f1d793143c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzJLwk4Lbu3E"
      },
      "source": [
        "#colab                    \n",
        "mlearner.load('stage-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2d8WiQnYRar"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12CplWJcYSuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2a4c7a-3c99-4d00-a55d-660955c73f77"
      },
      "source": [
        "mlearner.dls.device"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT5GiT4lYSuB"
      },
      "source": [
        "from fastai.torch_core import one_param"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76WuTlrvYSuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d3ba9d-cc6f-4565-e0a5-9909026002f6"
      },
      "source": [
        "one_param(mlearner.model).device"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayyjXIW_YGcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45b758a1-91f0-449c-ead0-21c9936e976d"
      },
      "source": [
        "#colab\n",
        "%%time\n",
        "valid_metrics = mlearner.validate();print(valid_metrics)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.03807949647307396, 0.9876999855041504]\n",
            "CPU times: user 1min 38s, sys: 3.28 s, total: 1min 41s\n",
            "Wall time: 5.69 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6cw2CjR7ckJ"
      },
      "source": [
        "# master_device = xm.xla_device()"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4aiYo7l7qNq"
      },
      "source": [
        "# mlearner.dls.device = master_device\n",
        "# mlearner.model.to(master_device)\n",
        "# mlearner.opt = None\n",
        "# mlearner.create_opt()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvMC68SExbZn"
      },
      "source": [
        "# %%time\n",
        "# valid_metrics = mlearner.validate(); valid_metrics"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECOD3xG0y40j"
      },
      "source": [
        "# mlearner.dls.device"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_7ijcwE4zGf"
      },
      "source": [
        "# one_param(mlearner.model).device"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi3_YNi67YbR"
      },
      "source": [
        ""
      ],
      "execution_count": 122,
      "outputs": []
    }
  ]
}